\section{Assured Partnership of AI and Humans}\label{sec:assuredPartnership}

Up to now, all the topics are based on data, algorithms, and models, with the interactions with humans mainly on requiring humans to e.g., label the training instances, and differentiate whether a perturbed image is an adversarial example. These interactions completely rely on humans' functional ability, without utilising their social aspects of intelligence. However, AI systems, or software/hardware systems with AI components, are penetrating our everyday life. It is therefore imperative to consider the partnership of humans and AI. 
From safety perspective, when humans and AI are interacting, the safety issues become more prominent, because unexpected behaviours of the AI systems may easily lead to bad consequences on their human partners.  

In this section, we will discuss several technical topics on how to assure the partnership of AI with humans. They include requiring a machine learning agent to provide auxiliary information beyond decisions, such as the confidence of each decision (i.e., \emph{uncertainty estimation}) and the explanation of individual decisions and the model in general (i.e., \emph{explainability and interpretability}), and understand human context (i.e., \emph{contextualisation}). These technical means can help strengthen the trust between humans and AI, and therefore enable their safe co-operation. 