%\newpage
\section{Reasoning Patterns}

As explained earlier, the construction of graphical models will enable our reasoning about a more complex relation between a set of random variables. In this section, we introduce a few typical reasoning patterns. 

\subsection{Causal Reasoning}

Causal reasoning considers how the changes of up-stream variables may affect the values of the down-stream variables. For our running example as in Figure~\ref{fig:cameratables}, it is for  an engineer to concern about how likely the car will stop given e.g., the quality of sensors (i.e., camera and/or radar). 

A typical process is to first compute a marginal probability such as 
\begin{equation}
    P(s_0) 
\end{equation}
which is the probability of the car does not stop. This can be computed by having 
\begin{equation}
\begin{array}{rl}
    P(s_0) = & \displaystyle\sum_{C,R,F,D,A} P(C,R,F,D,A,S=s_0) \\
    = & \displaystyle\sum_{i=0}^1\sum_{j=0}^1\sum_{k=0}^1\sum_{l=0}^1\sum_{m=0}^1 P(C=c_i,R=r_j,F=f_k,D=d_l,A=a_m,S=s_0)\\
    \approx & 0.62\\
\end{array}
\end{equation}
Then, we may consider a conditional probability such as 
\begin{equation}
    P(s_0|c_1) = \frac{P(s_0,c_1)}{P(c_1)} \approx 0.51
\end{equation}
which says that if we know that the camera captured the pedestrian, the probability of not stopped decreased to 0.51. Similarly, if  consider radar,  we have 
\begin{equation}
    P(s_0|r_1) = \frac{P(s_0,c_1)}{P(r_1)} \approx 0.44
\end{equation}

If both the camera and the radar are considered, we have 
\begin{equation}
    P(s_0|c_1,r_1) = \frac{P(s_0,c_1,r_1)}{P(c_1,r_1)} \approx 0.31
\end{equation}




\subsection{Evidential Reasoning}

A driver may want to know, subject to her own experience on e.g., car stopping and foggy weather, about the quality of the sensors. For example, first of all, she may have the following statistics from the vendor of the camera: 
\begin{equation}
    P(c_1) = 0.4 
\end{equation}
After observing that the car stopped, she might infer as follows, which shows that the probability increased to 0.51.  
\begin{equation}
    P(c_1|s_1) = \frac{P(c_1,s_1)}{P(s_1)} \approx 0.51 
\end{equation}
Intuitively, this may suggest that the specific camera installed on this car may perform above average. 

\subsection{Inter-causal Reasoning }

In addition to the above, it might be interested to understand how the causes of an event may affect each other. For example, consider the following 
\begin{equation}
    P(r_1|d_1) \approx 0.83 
\end{equation}
which suggests that once we know that the pedestrian is detected, the chance of radar captured the pedestrian is high, i.e., the quality of the radar is good. However, by having the following  
\begin{equation}
    P(r_1|d_1,c_1) \approx 0.75
\end{equation}
which is lower than $P(r_1|d_1)$, it suggests that the quality of the radar may not be as optimistic as it seems when only observing the detection result. The quality of the camera may also contribute well to the excellent detection result.  

\subsection{Practice}

First of all, we install a software package that can support the inference of probabilistic graphical models: 

\begin{cmds}
conda install pomegranate
\end{cmds}

To work with the package, we create a script \textbf{pedestrian\_detection.txt}. In the script, first of all, we import the package: 
\begin{lstlisting}[language=Python]
from pomegranate import *
\end{lstlisting}

Then, we encode a graphical model

\begin{lstlisting}[language=Python]
camera = DiscreteDistribution({'0': 0.6, '1': 0.4})
radar = DiscreteDistribution({'0': 0.5, '1': 0.5})
fog = ConditionalProbabilityTable(
        [['0', '0', 0.5],
         ['0', '1', 0.5],
         ['1', '0', 0.3],
         ['1', '1', 0.7]], [camera])
away = ConditionalProbabilityTable(
        [['0', '0', 0.2],
         ['0', '1', 0.8],
         ['1', '0', 0.6],
         ['1', '1', 0.4]], [radar])
detected = ConditionalProbabilityTable(
        [['0', '0', '0', 1.0],
         ['0', '0', '1', 0.0],
         ['0', '1', '0', 0.6],
         ['0', '1', '1', 0.4],
         ['1', '0', '0', 0.7],
         ['1', '0', '1', 0.3],
         ['1', '1', '0', 0.1],
         ['1', '1', '1', 0.9]], [camera, radar])
stopped = ConditionalProbabilityTable(
        [['0', '0', '0', 0.6],
         ['0', '0', '1', 0.4],
         ['0', '1', '0', 0.9],
         ['0', '1', '1', 0.1],
         ['1', '0', '0', 0.1],
         ['1', '0', '1', 0.9],
         ['1', '1', '0', 0.5],
         ['1', '1', '1', 0.5]], [detected, away])

s1 = Node(camera, name="camera")
s2 = Node(radar, name="radar")
s3 = Node(fog, name="fog")
s4 = Node(away, name="away")
s5 = Node(detected, name="detected")
s6 = Node(stopped, name="stopped")

model = BayesianNetwork("Pedestrian Detection Problem")
model.add_states(s1, s2, s3, s4, s5, s6)
model.add_edge(s1, s3)
model.add_edge(s1, s5)
model.add_edge(s2, s4)
model.add_edge(s2, s5)
model.add_edge(s5, s6)
model.add_edge(s4, s6)
model.bake()
\end{lstlisting}

After the above, we can start computing the probability values: 
\begin{lstlisting}[language=Python]
#### P(s0,c1)
query = ['1', None, None, None, None, '0']
ps0c1 = 0 
for j1 in range(2): 
    for j2 in range(2): 
        for j3 in range(2): 
            for j4 in range(2): 
                ps0c1 += model.probability([['1', str(j1), str(j2), str(j3), str(j4), '0']])
print("the probability of the car does not stop but the camera captured the pedestrian P(s0,c1): %s\n"%(ps0c1))

### P(c1)
query = ['1', None, None, None, None, None]
pc1 = 0 
for j1 in range(2): 
    for j2 in range(2): 
        for j3 in range(2): 
            for j4 in range(2): 
                for j5 in range(2): 
                    pc1 += model.probability([['1', str(j1), str(j2), str(j3), str(j4), str(j5)]])
print("the probability of camera captured the pedestrian P(c1): %s\n"%pc1)

#### P(s0|c1)
print("the conditional probability of the car does not stop when the camera captured the pedestrian P(s0|c1)): %s\n"%(ps0c1/pc1))
\end{lstlisting}
